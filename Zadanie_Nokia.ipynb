{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "## Initial Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Part of the task at hand is to guess where does the data come from and what object it depicts. Starting off with just one \"CA\" dataset will make it easier to get acquainted with the data - variable **X** will be assigned to '**x_train_CA1.csv**' and **y** to '**y_train_CA1.csv**'. The data can be loaded with pandas command **pd.read_csv()** and since there are no header names within the files, \"header\" is set to None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987924</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>0.987059</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657933</td>\n",
       "      <td>0.762965</td>\n",
       "      <td>0.151526</td>\n",
       "      <td>0.022457</td>\n",
       "      <td>0.358574</td>\n",
       "      <td>0.423731</td>\n",
       "      <td>0.238467</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.374880</td>\n",
       "      <td>0.590332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016640</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021438</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100402</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162879</td>\n",
       "      <td>0.089546</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.055201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.068437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678704</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>0.982009</td>\n",
       "      <td>0.998096</td>\n",
       "      <td>0.682020</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.979035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186196</td>\n",
       "      <td>0.120355</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.052493</td>\n",
       "      <td>0.228079</td>\n",
       "      <td>0.046975</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685063</td>\n",
       "      <td>0.645223</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>0.344360</td>\n",
       "      <td>0.659689</td>\n",
       "      <td>0.654306</td>\n",
       "      <td>0.669522</td>\n",
       "      <td>0.308953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915907</td>\n",
       "      <td>0.658589</td>\n",
       "      <td>0.285195</td>\n",
       "      <td>0.183857</td>\n",
       "      <td>0.312588</td>\n",
       "      <td>0.143706</td>\n",
       "      <td>0.407940</td>\n",
       "      <td>0.490527</td>\n",
       "      <td>0.615597</td>\n",
       "      <td>0.514540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.022080</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019247</td>\n",
       "      <td>0.054245</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.000000  0.987924  0.982271  1.000000  1.000000  0.981124  0.987059   \n",
       "1  0.016640  0.004779  0.022958  0.000000  0.021438  0.017773  0.010535   \n",
       "2  1.000000  0.678704  0.987529  0.982009  0.998096  0.682020  0.998551   \n",
       "3  0.685063  0.645223  0.671967  0.344360  0.659689  0.654306  0.669522   \n",
       "4  0.018483  0.000000  0.000000  0.000000  0.000000  0.000000  0.013401   \n",
       "\n",
       "         7         8         9   ...        86        87        88        89  \\\n",
       "0  0.988435  0.000000  0.000000  ...  0.657933  0.762965  0.151526  0.022457   \n",
       "1  0.023406  0.000000  0.000000  ...  0.100402  0.085974  0.000000  0.162879   \n",
       "2  0.979035  0.000000  0.003804  ...  0.186196  0.120355  0.015417  0.072767   \n",
       "3  0.308953  0.000000  0.000000  ...  0.915907  0.658589  0.285195  0.183857   \n",
       "4  0.022080  0.013823  0.000000  ...  0.014698  0.006794  0.000000  0.019247   \n",
       "\n",
       "         90        91        92        93        94        95  \n",
       "0  0.358574  0.423731  0.238467  0.029127  0.374880  0.590332  \n",
       "1  0.089546  0.038443  0.055201  0.000000  0.018842  0.068437  \n",
       "2  0.052493  0.228079  0.046975  0.127654  0.000000  0.087367  \n",
       "3  0.312588  0.143706  0.407940  0.490527  0.615597  0.514540  \n",
       "4  0.054245  0.016252  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('Data/x_train_CA1.csv', header=None)\n",
    "y = pd.read_csv('Data/y_train_CA1.csv', header=None)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 96)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.406296</td>\n",
       "      <td>0.302534</td>\n",
       "      <td>0.389756</td>\n",
       "      <td>0.367475</td>\n",
       "      <td>0.406316</td>\n",
       "      <td>0.302119</td>\n",
       "      <td>0.390031</td>\n",
       "      <td>0.367795</td>\n",
       "      <td>0.099622</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112631</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.078453</td>\n",
       "      <td>0.075324</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.080190</td>\n",
       "      <td>0.078643</td>\n",
       "      <td>0.078273</td>\n",
       "      <td>0.078304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.389307</td>\n",
       "      <td>0.323628</td>\n",
       "      <td>0.390292</td>\n",
       "      <td>0.384839</td>\n",
       "      <td>0.389539</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.389898</td>\n",
       "      <td>0.384444</td>\n",
       "      <td>0.262318</td>\n",
       "      <td>0.256830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215503</td>\n",
       "      <td>0.207789</td>\n",
       "      <td>0.185831</td>\n",
       "      <td>0.178440</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>0.184609</td>\n",
       "      <td>0.182633</td>\n",
       "      <td>0.180890</td>\n",
       "      <td>0.185323</td>\n",
       "      <td>0.183647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.340362</td>\n",
       "      <td>0.312962</td>\n",
       "      <td>0.329896</td>\n",
       "      <td>0.322059</td>\n",
       "      <td>0.337146</td>\n",
       "      <td>0.310948</td>\n",
       "      <td>0.327624</td>\n",
       "      <td>0.322533</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019082</td>\n",
       "      <td>0.022194</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.015333</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.014737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.658765</td>\n",
       "      <td>0.677412</td>\n",
       "      <td>0.672623</td>\n",
       "      <td>0.680219</td>\n",
       "      <td>0.655968</td>\n",
       "      <td>0.676093</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103529</td>\n",
       "      <td>0.091997</td>\n",
       "      <td>0.056775</td>\n",
       "      <td>0.056681</td>\n",
       "      <td>0.065065</td>\n",
       "      <td>0.057171</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>0.065865</td>\n",
       "      <td>0.053930</td>\n",
       "      <td>0.053956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1060.000000  1060.000000  1060.000000  1060.000000  1060.000000   \n",
       "mean      0.406296     0.302534     0.389756     0.367475     0.406316   \n",
       "std       0.389307     0.323628     0.390292     0.384839     0.389539   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.005148     0.000239     0.003323     0.000565     0.004901   \n",
       "50%       0.340362     0.312962     0.329896     0.322059     0.337146   \n",
       "75%       0.679549     0.658765     0.677412     0.672623     0.680219   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  1060.000000  1060.000000  1060.000000  1060.000000  1060.000000  ...   \n",
       "mean      0.302119     0.390031     0.367795     0.099622     0.096031  ...   \n",
       "std       0.323106     0.389898     0.384444     0.262318     0.256830  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.001013     0.006153     0.002287     0.000000     0.000000  ...   \n",
       "50%       0.310948     0.327624     0.322533     0.003816     0.002947  ...   \n",
       "75%       0.655968     0.676093     0.674163     0.018795     0.017718  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "                86           87           88           89           90  \\\n",
       "count  1060.000000  1060.000000  1060.000000  1060.000000  1060.000000   \n",
       "mean      0.112631     0.109139     0.078453     0.075324     0.078828   \n",
       "std       0.215503     0.207789     0.185831     0.178440     0.182490   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000641     0.000000     0.000000     0.000000   \n",
       "50%       0.019082     0.022194     0.015427     0.016602     0.016054   \n",
       "75%       0.103529     0.091997     0.056775     0.056681     0.065065   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                91           92           93           94           95  \n",
       "count  1060.000000  1060.000000  1060.000000  1060.000000  1060.000000  \n",
       "mean      0.078777     0.080190     0.078643     0.078273     0.078304  \n",
       "std       0.184609     0.182633     0.180890     0.185323     0.183647  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.014165     0.015333     0.015420     0.015567     0.014737  \n",
       "75%       0.057171     0.059602     0.065865     0.053930     0.053956  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 96 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1060 entries, 0 to 1059\n",
      "Data columns (total 96 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1060 non-null   float64\n",
      " 1   1       1060 non-null   float64\n",
      " 2   2       1060 non-null   float64\n",
      " 3   3       1060 non-null   float64\n",
      " 4   4       1060 non-null   float64\n",
      " 5   5       1060 non-null   float64\n",
      " 6   6       1060 non-null   float64\n",
      " 7   7       1060 non-null   float64\n",
      " 8   8       1060 non-null   float64\n",
      " 9   9       1060 non-null   float64\n",
      " 10  10      1060 non-null   float64\n",
      " 11  11      1060 non-null   float64\n",
      " 12  12      1060 non-null   float64\n",
      " 13  13      1060 non-null   float64\n",
      " 14  14      1060 non-null   float64\n",
      " 15  15      1060 non-null   float64\n",
      " 16  16      1060 non-null   float64\n",
      " 17  17      1060 non-null   float64\n",
      " 18  18      1060 non-null   float64\n",
      " 19  19      1060 non-null   float64\n",
      " 20  20      1060 non-null   float64\n",
      " 21  21      1060 non-null   float64\n",
      " 22  22      1060 non-null   float64\n",
      " 23  23      1060 non-null   float64\n",
      " 24  24      1060 non-null   float64\n",
      " 25  25      1060 non-null   float64\n",
      " 26  26      1060 non-null   float64\n",
      " 27  27      1060 non-null   float64\n",
      " 28  28      1060 non-null   float64\n",
      " 29  29      1060 non-null   float64\n",
      " 30  30      1060 non-null   float64\n",
      " 31  31      1060 non-null   float64\n",
      " 32  32      1060 non-null   float64\n",
      " 33  33      1060 non-null   float64\n",
      " 34  34      1060 non-null   float64\n",
      " 35  35      1060 non-null   float64\n",
      " 36  36      1060 non-null   float64\n",
      " 37  37      1060 non-null   float64\n",
      " 38  38      1060 non-null   float64\n",
      " 39  39      1060 non-null   float64\n",
      " 40  40      1060 non-null   float64\n",
      " 41  41      1060 non-null   float64\n",
      " 42  42      1060 non-null   float64\n",
      " 43  43      1060 non-null   float64\n",
      " 44  44      1060 non-null   float64\n",
      " 45  45      1060 non-null   float64\n",
      " 46  46      1060 non-null   float64\n",
      " 47  47      1060 non-null   float64\n",
      " 48  48      1060 non-null   float64\n",
      " 49  49      1060 non-null   float64\n",
      " 50  50      1060 non-null   float64\n",
      " 51  51      1060 non-null   float64\n",
      " 52  52      1060 non-null   float64\n",
      " 53  53      1060 non-null   float64\n",
      " 54  54      1060 non-null   float64\n",
      " 55  55      1060 non-null   float64\n",
      " 56  56      1060 non-null   float64\n",
      " 57  57      1060 non-null   float64\n",
      " 58  58      1060 non-null   float64\n",
      " 59  59      1060 non-null   float64\n",
      " 60  60      1060 non-null   float64\n",
      " 61  61      1060 non-null   float64\n",
      " 62  62      1060 non-null   float64\n",
      " 63  63      1060 non-null   float64\n",
      " 64  64      1060 non-null   float64\n",
      " 65  65      1060 non-null   float64\n",
      " 66  66      1060 non-null   float64\n",
      " 67  67      1060 non-null   float64\n",
      " 68  68      1060 non-null   float64\n",
      " 69  69      1060 non-null   float64\n",
      " 70  70      1060 non-null   float64\n",
      " 71  71      1060 non-null   float64\n",
      " 72  72      1060 non-null   float64\n",
      " 73  73      1060 non-null   float64\n",
      " 74  74      1060 non-null   float64\n",
      " 75  75      1060 non-null   float64\n",
      " 76  76      1060 non-null   float64\n",
      " 77  77      1060 non-null   float64\n",
      " 78  78      1060 non-null   float64\n",
      " 79  79      1060 non-null   float64\n",
      " 80  80      1060 non-null   float64\n",
      " 81  81      1060 non-null   float64\n",
      " 82  82      1060 non-null   float64\n",
      " 83  83      1060 non-null   float64\n",
      " 84  84      1060 non-null   float64\n",
      " 85  85      1060 non-null   float64\n",
      " 86  86      1060 non-null   float64\n",
      " 87  87      1060 non-null   float64\n",
      " 88  88      1060 non-null   float64\n",
      " 89  89      1060 non-null   float64\n",
      " 90  90      1060 non-null   float64\n",
      " 91  91      1060 non-null   float64\n",
      " 92  92      1060 non-null   float64\n",
      " 93  93      1060 non-null   float64\n",
      " 94  94      1060 non-null   float64\n",
      " 95  95      1060 non-null   float64\n",
      "dtypes: float64(96)\n",
      "memory usage: 795.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  1.000000\n",
       "1  0.000000\n",
       "2  0.000000\n",
       "3  0.014763\n",
       "4  0.013082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1060 entries, 0 to 1059\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1060 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 8.4 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.053012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.014140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1060.000000\n",
       "mean      0.053012\n",
       "std       0.209649\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.002117\n",
       "75%       0.014140\n",
       "max       1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having explored the data, it shows that:\n",
    "- X has 96 features (columns), which names have been encoded with integer numbers between 0 and 95\n",
    "- X has 1060 observations (rows)\n",
    "- X contains rational numbers between 0 and 1. No null values per column\n",
    "- y has 1 column and 1060 rows. No null values\n",
    "- As mentioned in the task description, y should contain binary labels (0 or 1) but has some noise \n",
    "\n",
    "Conclusions:\n",
    "- X contains 96 features, which is a more than desired. Some sort of Dimension Reduction will be useful moving forward\n",
    "- Some rows in X have higher Standard Deviation (std) than other and so - higher variance, which is desired for ML modelling. Other columns which don't have such high std will most likely be dropped in the process of Dimension Reduction\n",
    "- The X data is in a \"tidy\" format so it doesn't need much cleaning\n",
    "- Noise in the y dataset needs to be dealt with\n",
    "\n",
    "\n",
    "## Assessment of \"CA\" object\n",
    "As hinted in the task description - one might think about the data as an \"x-ray under different angles or CAT scan\". Given the fact that the X data has 96 features which contain rational numbers between 0 and 1, a single column might be containing values for a vector which is pointed in a specific direction in either two or three dimensions.\n",
    "\n",
    "Having this in mind, perhaps a reasonable guess is that the data depicts some sort of a multi-dimensional scan for a given telecommunication tower.\n",
    "\n",
    "## Visualizing and removing y noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y[0].plot.hist(by=0, bins=20, xticks=np.arange(min(y[0]), max(y[0])+0.1, 0.1), figsize=(12,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above shows that all of the observations are close to either 1 or 0 with no observations distributed in the middle. Speficically - there are no observations beteween $(0.05, 0.95)$ judging by the number of histogram bins equal 20, which divide the x-axis into equal segments of length 0.05.\n",
    "\n",
    "Having observations in the middle would be problematic because they would be hard to classify as either 0 or 1 without any prior knowledge of their distribution. This means, however, that it is most likely safe to assume that values close to 1 can be classified as \"1\" and values close to 0 as \"0\" moving forward. This can be achieved by transforming the \"float\" column data type into \"integer\".\n",
    "\n",
    "Another key observation here is that the CA1 y data is unbalanced - there are far more 0's than there are 1's, which means that a performance metric other than accuracy might be needed later during Machine Learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1010\n",
      "1      50\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y[0] = round(y[0]).astype(int)\n",
    "assert y[(y[0] > 0) & (y[0] < 1)][0].any() == False\n",
    "print(y[0].value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above shows that y has been succesfully turned into a dataframe without any previous noise - all observations are now equal to 0 or 1. Specifically there are 50 observations labeled as 1 as 1010 labeled as 0.\n",
    "\n",
    "## Metadata\n",
    "So far only one of the CA objects was explored: CA1. Based on this, however, some assumtions can be made of how to check and clean the data if it were concatenated into metadata. The assertions in the code below check **for each CA object** if:\n",
    "- there are no values in y_train distributed between $[0.05, 0.95]$\n",
    "- the rows in x_train dataset is equal to y_train dataset\n",
    "- the minimum and maximum is indeed equal to 0 and 1 respectively for both x_train and y_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(1, 18):\n",
    "    x_str = 'Data/x_train_CA' + str(index) + '.csv'\n",
    "    y_str = 'Data/y_train_CA' + str(index) + '.csv'\n",
    "    X_test = pd.read_csv(x_str, header=None)\n",
    "    y_test = pd.read_csv(y_str, header=None)\n",
    "    \n",
    "    # Check there are any observations between (0.05, 0.95) in y_data\n",
    "    assert y_test[(y_test[0] > 0.05) & (y_test[0] < 0.95)][0].any() == False\n",
    "    \n",
    "    #Check if X and y length are equal\n",
    "    assert X_test.shape[0] == y_test.shape[0]\n",
    "    \n",
    "    # Check the maximum/minimum value of y_test\n",
    "    assert y_test[0].max() <= 1\n",
    "    assert y_test[0].min() >= 0\n",
    "    \n",
    "    # Check the maximum/minimum value across the whole X_test dataframe\n",
    "    assert X_test.max().max() <= 1\n",
    "    assert X_test.min().min() >= 0\n",
    "\n",
    "# Delete X_test and y_test for memory efficiency\n",
    "del X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the code above passed without raising any errors the data can now be concatenated to create metadata which will be called \"X_meta\" for all \"x_train\" datasets and \"y_meta\" for all \"y_train\" datasets. As mentioned in the task description:\n",
    "\n",
    "\"*It must be possible to map response produced back to specific CA*\"\n",
    "\n",
    "and in order to achieve this, each row number will be prefixed with with \"CA#_\" where the \"#\" is the number of the CA object.\n",
    "\n",
    "### Data concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial X_meta and y_meta dataframe\n",
    "x_str = 'Data/x_train_CA1.csv'\n",
    "y_str = 'Data/y_train_CA1.csv'\n",
    "X_meta = pd.read_csv(x_str, header=None)\n",
    "y_meta = pd.read_csv(y_str, header=None)\n",
    "\n",
    "# Change label types from float to int\n",
    "y_meta[0] = round(y_meta[0]).astype(int)\n",
    "\n",
    "\n",
    "X_meta = X_meta.set_index(\"CA1_\" + X_meta.index.astype(str))\n",
    "y_meta = y_meta.set_index(\"CA1_\" + y_meta.index.astype(str))\n",
    "\n",
    "# Concatenate additional dataframes to the existing X_meta and y_meta\n",
    "for i in range(2, 18):\n",
    "    x_str = 'Data/x_train_CA' + str(i) + '.csv'\n",
    "    y_str = 'Data/y_train_CA' + str(i) + '.csv'\n",
    "    X_temp = pd.read_csv(x_str, header=None)\n",
    "    y_temp = pd.read_csv(y_str, header=None)\n",
    "    \n",
    "    # Change label types from float to int\n",
    "    y_temp[0] = round(y_temp[0]).astype(int)\n",
    "    \n",
    "    X_temp = X_temp.set_index(\"CA\" + str(i) + \"_\" + X_temp.index.astype(str))\n",
    "    y_temp = y_temp.set_index(\"CA\" + str(i) + \"_\" + y_temp.index.astype(str))\n",
    "    \n",
    "    X_meta = pd.concat([X_meta, X_temp])\n",
    "    y_meta = pd.concat([y_meta, y_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon concatenating data the one thing worth checking is the balance between 0 and 1 labels in the concatenated y_meta dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16008\n",
       "1     1770\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_meta[0].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is plain that the data is imbalanced as there are far more 0's than 1's - nearly 10 times more.\n",
    "\n",
    "It could be assumed then, that it is more desirable to correctly classify 1's rather than 0's and so a performance metric other than accuracy would be needed during model evaluation. In such case the metric of choice will be **recall**, but since it isn't specified within the task that it is more desirable to correctly classify 1's, the models below will also be evaluated with **accuracy** for overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction - Feature Selection\n",
    "The \"X_meta\" dataset contains 96 features which are most likely too many. By utilizing Principal Component Analysis it can be calculated what is the explained variance ratio for each feature and discard the columns which wouldn't contribute much in ML modelling by creating a new \"reduced_X\" dataset. This data is created with a for loop over the number of features chosen in order to retain the \"CA#_\" naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56639956 0.76476436 0.81768407 0.85088952 0.87343171 0.88644735\n",
      " 0.89837954 0.90931184 0.91831672 0.9246656 ]\n",
      "Number of Principal Components chosen: 4\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "std_df = scaler.fit_transform(X_meta)\n",
    "pca = PCA()\n",
    "pick_cols = pca.fit_transform(X_meta)\n",
    "\n",
    "ratio = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# How much variance to be chosen\n",
    "n = sum(ratio < 0.86)\n",
    "print(ratio[:10])\n",
    "print(\"Number of Principal Components chosen: \" + str(n))\n",
    "\n",
    "reduced_X = X_meta.drop(X_meta.columns, axis=1)\n",
    "for i in range(n):\n",
    "    reduced_X[i] = pick_cols[:,i]\n",
    "\n",
    "# print(reduced_X.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "Now that the data has been prepared we will move onto the next step - ML Modelling. Five Machine Learning models will be explored for the classification problem at hand:\n",
    "1. Support Vector Machine\n",
    "2. Logistic Regression\n",
    "3. K-Neighbors Classifier\n",
    "4. Decision Tree Classifier\n",
    "5. Voting Classifier consisting of 3 of the models listed above\n",
    "\n",
    "Because it isn't clear which is more important: correctly classifing 1's over 0's or correctly classyfing both 1's and 0's each of the models will be tuned using **Grid Search Cross-Validation** while being evaluated by one of the two metrics:\n",
    "- **accuracy** for overall model performance on correctly classifing both 0's and 1's\n",
    "- **recall** for correctly classifing 1's\n",
    "\n",
    "### Split the data into train and test portions\n",
    "Since there are over 17k observations, splitting the data into 85% train size and 15% test size should be sufficient for later model evaluation. The random_state of the train_test_split has been set to 0 for reproducibilty.\n",
    "\n",
    "Defining a \"model_evaluation\" function will make it easier to evaluate models later on depending on the choice of performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reduced_X, y_meta, test_size=0.15, random_state=0, stratify=y_meta)\n",
    "\n",
    "def model_evaluation(model, param, performance_metric, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    \"\"\"\"A function for evaluating ML model performance depending\n",
    "    on a performance_metric of choice. Takes in as arguments:\n",
    "    - model: ML model\n",
    "    - params: Grid Search CV parameters to check in a dictionary of lists format\n",
    "    - performance_metric: either 'accuracy' or 'recall'\n",
    "    \n",
    "    The function utilizes Grid Search for finding the best model Hyperparameters\n",
    "    and fits the data to the model. Once this is done the function prints the\n",
    "    best Grid Search parameters, Confusion matrix and performance score for a\n",
    "    given model and performance metric.\n",
    "    \n",
    "    Function eturns the performance score of choice: accuracy or recall depending\n",
    "    on the performance_metric variable.\"\"\"\n",
    "    \n",
    "    assert performance_metric in ['accuracy', 'recall']\n",
    "    \n",
    "    searcher = GridSearchCV(model, param, scoring=performance_metric, n_jobs=-1, cv=10)\n",
    "    searcher.fit(X_train, np.ravel(y_train))\n",
    "    y_pred = searcher.predict(X_test)\n",
    "\n",
    "    print(\"Best CV params\", searcher.best_params_)\n",
    "    # print(\"Best CV score:\", searcher.best_score_)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    if performance_metric == 'accuracy':\n",
    "        performance_score = accuracy_score(y_test, y_pred)\n",
    "    else:\n",
    "        performance_score = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(performance_metric.capitalize() + \" score of best grid search hyperparameters: \" + str(performance_score))\n",
    "    \n",
    "    # tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # print(tp)\n",
    "    # print(fn)\n",
    "    # print(fp)\n",
    "    # print(tp/(tp+fn)) # recall\n",
    "    \n",
    "    return performance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (accuracy)\n",
    "\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 0.3, 'kernel': 'rbf'}\n",
      "[[2369   32]\n",
      " [  74  192]]\n",
      "Accuracy score of best grid search hyperparameters: 0.9602549681289839\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "parameters = {'C':[0.1, 0.3, 1, 3], 'kernel':['rbf','poly']}\n",
    "\n",
    "svc_accuracy = model_evaluation(svc, parameters, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 0.001}\n",
      "[[2370   31]\n",
      " [  71  195]]\n",
      "Accuracy score of best grid search hyperparameters: 0.9617547806524185\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "parameters = {'C':[0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]}\n",
    "\n",
    "logreg_accuracy = model_evaluation(logreg, parameters, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'n_neighbors': 6}\n",
      "[[2366   35]\n",
      " [  77  189]]\n",
      "Accuracy score of best grid search hyperparameters: 0.958005249343832\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "\n",
    "knn_accuracy = model_evaluation(knn, parameters, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'min_samples_leaf': 7, 'min_samples_split': 5}\n",
      "[[2345   56]\n",
      " [  78  188]]\n",
      "Accuracy score of best grid search hyperparameters: 0.9497562804649419\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "parameters = {'min_samples_leaf':[1,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6,7]}\n",
    "\n",
    "dt_accuracy = model_evaluation(dt, parameters, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "\n",
    "Combination of three other Classification ML Models with their best respective hyperparameters for best accuracy:\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2368   33]\n",
      " [  73  193]]\n",
      "Accuracy score of best grid search hypers: 0.9602549681289839\n"
     ]
    }
   ],
   "source": [
    "clf_svc = SVC(C=0.3, kernel='rbf')\n",
    "clf_lr = LogisticRegression(C=0.001)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "clf_voting = VotingClassifier(voting='hard', estimators=[\n",
    "    ('svc', clf_svc),\n",
    "    ('lr', clf_lr),\n",
    "    ('knn', clf_knn)\n",
    "])\n",
    "\n",
    "clf_voting.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "clf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score of best grid search hypers:\", clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (Recall)\n",
    "\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 3, 'kernel': 'rbf'}\n",
      "[[2371   30]\n",
      " [  73  193]]\n",
      "Recall score of best grid search hyperparameters: 0.7255639097744361\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "parameters = {'C':[0.1, 0.3, 1, 3], 'kernel':['rbf','poly']}\n",
    "\n",
    "svc_recall = model_evaluation(svc, parameters, 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 1}\n",
      "[[2359   42]\n",
      " [  68  198]]\n",
      "Recall score of best grid search hyperparameters: 0.7443609022556391\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "parameters = {'C':[0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]}\n",
    "\n",
    "logreg_recall = model_evaluation(logreg, parameters, 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'n_neighbors': 5}\n",
      "[[2358   43]\n",
      " [  73  193]]\n",
      "Recall score of best grid search hyperparameters: 0.7255639097744361\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "\n",
    "knn_recall = model_evaluation(knn, parameters, 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'min_samples_leaf': 3, 'min_samples_split': 5}\n",
      "[[2328   73]\n",
      " [  72  194]]\n",
      "Recall score of best grid search hyperparameters: 0.7293233082706767\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "parameters = {'min_samples_leaf':[1,2,3,4,5,6], 'min_samples_split':[2,3,4,5,6]}\n",
    "\n",
    "dt_recall = model_evaluation(dt, parameters, 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "\n",
    "Combination of three other Classification ML Models with their best respective hyperparameters for best Recall score:\n",
    "- Logistic Regression\n",
    "- K-Neighbors Classifier\n",
    "- Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2358   43]\n",
      " [  71  195]]\n",
      "Recall score of best grid search hyperparameters: 0.7330827067669173\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(C=1)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=5)\n",
    "\n",
    "clf_voting = VotingClassifier(voting='hard', estimators=[\n",
    "    ('lr', clf_lr),\n",
    "    ('knn', clf_knn),\n",
    "    ('dt', clf_dt)\n",
    "])\n",
    "\n",
    "clf_voting.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "clf_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall score of best grid search hyperparameters:\", clf_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "After:\n",
    "- exploring and cleaning the y_train data\n",
    "- creating a metadata dataframe out of all \"CA\" datasets\n",
    "- reducing the X_meta dimension by utilizing Principial Component Analysis\n",
    "\n",
    "5 different models were evaluated using two performance metrics: accuracy and recall. The results are shown in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.744361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.960255</td>\n",
       "      <td>0.725564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting Classifier</th>\n",
       "      <td>0.960255</td>\n",
       "      <td>0.733083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Neighbors</th>\n",
       "      <td>0.958005</td>\n",
       "      <td>0.725564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.949756</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy    Recall\n",
       "Model                                     \n",
       "Logistic Regression     0.961755  0.744361\n",
       "Support Vector Machine  0.960255  0.725564\n",
       "Voting Classifier       0.960255  0.733083\n",
       "K-Neighbors             0.958005  0.725564\n",
       "Decision Tree           0.949756  0.729323"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': [ 'Support Vector Machine',\n",
    "              'Logistic Regression', \n",
    "              'K-Neighbors',\n",
    "              'Decision Tree',\n",
    "              'Voting Classifier'],\n",
    "    'Accuracy': [svc_accuracy,\n",
    "                 logreg_accuracy, \n",
    "                 knn_accuracy,\n",
    "                 dt_accuracy,\n",
    "                 clf_accuracy],\n",
    "    'Recall': [svc_recall,\n",
    "               logreg_recall, \n",
    "               knn_recall,\n",
    "               dt_recall,\n",
    "               clf_recall],\n",
    "})\n",
    "result_df = results.sort_values(by='Accuracy', ascending=False)\n",
    "result_df = result_df.set_index('Model')\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows that the model with the best **accuracy** is **Logistic Regression** with the regularization parameter C set to 0.001. It shows an impressive score of **96.18%** accuracy which means that it is able to corectly classify such percent of labels: both 0's and 1's. It is closely followed by both Support Vector Machine and Voting Classifier, which both have an accuracy of 96.03%.\n",
    "\n",
    "If, however, the desired outcome of a model is to classify correctly 1's over 0's then the performance metric of choice was **recall** and the best model was, again, **Logistic Regression** with the parameter C set to 1. Despite the fact that it was the best performing model, the recall score was only as high as 0.7444 which means that **74.44%** of 1's were classified correctly out of all 1's. This leads to the conclusion that the model still performs well in those regards but a bit worse in contrast to accuracy. Recall would most likely increase if the dataset contained more observations labeled as \"1\" from which the model could learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
